**Kafka只对“已提交”的消息做有限度的持久化保证**

## 已提交的消息

当Kafka的若干个（一个或多个或全部，取决于用户对“已提交”的定义）Broker成功地接收到一条消息并写入日志文件后，这条消息在Kafka看来就成为了“已提交”消息。

## 有限度的持久化保证

Kafka不能保证在任何情况下都做到不丢失消息。**Kafka不丢消息的前提是消息至少存在于一个Broker上**。



## “消息丢失”案例

### 生产者程序丢失数据

异步发送（发射后不管）消息到Kafka的方式很可能由于网络抖动问题导致消息根本没有发送到Broker端；又或者消息（比如消息过大）本身不合格导致Broker拒绝接收，Kafka不认为消息是已提交的。

解决方式是：使用同步或者使用带有回调通知（callback）的发送API。这样出现了消息提交失败的情况，可以针对性地进行处理。

### 消费者程序丢失数据

对于消费“位移”，Kafka消费者客户端默认是自动提交的，多线程异步消费时可能出现这种情况：消费者A消费到offset为9，消费者B消费到offset为11，如果此时消费者A消息处理遇到了问题而处理失败，那么所负责的消息没有处理成功但是位移可能由于自动提交而被更新了，就会导致offset为9的消息“丢失”。或者消费者A还正在处理消息，而消费者B已经消费完成并通过自动提交更新了offset，如果此时消费者出现了重启，那么将从最新的offset为12的消息继续消费，那么消息9也将丢失。

